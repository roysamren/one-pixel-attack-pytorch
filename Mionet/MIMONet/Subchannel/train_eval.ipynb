{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c19563cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '../src'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "    \n",
    "from utils import MIMONetDataset, DeepONetDataset, ChannelScaler\n",
    "from mimonet import MIMONet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68626d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# check if GPU is available and set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbcf3b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set working directory\n",
    "working_dir = \".\"\n",
    "data_dir = os.path.join(working_dir, \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127c3cb8",
   "metadata": {},
   "source": [
    "## load datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9662230f",
   "metadata": {},
   "source": [
    "### Load sharing parameters/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e26d6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trunk dataset\n",
    "trunk_input = np.load(os.path.join(data_dir, \"share/trunk_input.npz\"))['trunk']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ab5c36",
   "metadata": {},
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a28faea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_branch_1 shape: (4000, 100)\n",
      "train_branch_2 shape: (4000, 2)\n",
      "train_target shape: (4000, 1733, 3)\n"
     ]
    }
   ],
   "source": [
    "# training data\n",
    "train_branch = np.load(os.path.join(data_dir, \"training/train_branch_input.npz\"))\n",
    "train_branch_1 = train_branch['func_params']\n",
    "train_branch_2 = train_branch['stat_params']\n",
    "\n",
    "# [samples, channel, gridpoints]\n",
    "train_target = np.load(os.path.join(data_dir, \"training/train_target.npz\"))['target']\n",
    "# convert to [samples, gridpoints, channel]\n",
    "train_target = np.moveaxis(train_target, 1, 2)\n",
    "\n",
    "print(\"train_branch_1 shape:\", train_branch_1.shape)\n",
    "print(\"train_branch_2 shape:\", train_branch_2.shape)\n",
    "print(\"train_target shape:\", train_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9dc288a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the functional input data using predefined mean and std\n",
    "f_mean = np.load(os.path.join(data_dir, \"share/func_mean_std_params.npz\"))['mean']\n",
    "f_std = np.load(os.path.join(data_dir, \"share/func_mean_std_params.npz\"))['std']\n",
    "\n",
    "train_branch_1 = (train_branch_1 - f_mean) / f_std\n",
    "\n",
    "# scaling the static input data using predefined mean and std\n",
    "s_mean = np.load(os.path.join(data_dir, \"share/stat_mean_std_params.npz\"))['mean']\n",
    "s_std = np.load(os.path.join(data_dir, \"share/stat_mean_std_params.npz\"))['std']\n",
    "\n",
    "for i in range(s_mean.shape[0]):\n",
    "    train_branch_2[:, i] = (train_branch_2[:, i] - s_mean[i]) / s_std[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b88f645",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54556d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_branch_1 shape: (1000, 100)\n",
      "test_branch_2 shape: (1000, 2)\n",
      "test_target shape: (1000, 1733, 3)\n"
     ]
    }
   ],
   "source": [
    "test_branch = np.load(os.path.join(data_dir, \"test/test_branch_input.npz\"))\n",
    "test_branch_1 = test_branch['func_params']\n",
    "test_branch_2 = test_branch['stat_params']\n",
    "\n",
    "test_target = np.load(os.path.join(data_dir, \"test/test_target.npz\"))['target']\n",
    "test_target = np.moveaxis(test_target, 1, 2)\n",
    "\n",
    "print(\"test_branch_1 shape:\", test_branch_1.shape)\n",
    "print(\"test_branch_2 shape:\", test_branch_2.shape)\n",
    "print(\"test_target shape:\", test_target.shape)\n",
    "\n",
    "# scaling the functional input data using predefined mean and std\n",
    "test_branch_1 = (test_branch_1 - f_mean) / f_std\n",
    "# scaling the static input data using predefined mean and std\n",
    "for i in range(s_mean.shape[0]):\n",
    "    test_branch_2[:, i] = (test_branch_2[:, i] - s_mean[i]) / s_std[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dddd92",
   "metadata": {},
   "source": [
    "### Scaling the target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "688e7a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the target data\n",
    "'''  \n",
    "note: reverse the scaling for the target data\n",
    "train_target = scaler.inverse_transform(train_target_scaled)\n",
    "test_target = scaler.inverse_transform(test_target_scaled)\n",
    "'''\n",
    "scaler = ChannelScaler(method='minmax', feature_range=(-1, 1))\n",
    "scaler.fit(train_target)\n",
    "train_target_scaled = scaler.transform(train_target)\n",
    "test_target_scaled = scaler.transform(test_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d87ae6a",
   "metadata": {},
   "source": [
    "## Torch Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf71b1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset and dataloader\n",
    "test_dataset = MIMONetDataset(\n",
    "    [test_branch_1, test_branch_2],  # branch_data_list\n",
    "    trunk_input,                     # trunk_data\n",
    "    test_target_scaled               # target_data\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,  # set to 1 for testing\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a754121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MIMONetDataset(\n",
    "    [train_branch_1, train_branch_2],  # branch_data_list\n",
    "    trunk_input,                       # trunk_data\n",
    "    train_target_scaled                # target_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120b2674",
   "metadata": {},
   "source": [
    "## MIMONet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57223d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 1,696,259\n"
     ]
    }
   ],
   "source": [
    "# Architecture parameters\n",
    "dim = 256\n",
    "branch_input_dim1 = 100\n",
    "branch_input_dim2 = 2\n",
    "trunk_input_dim = 2\n",
    "\n",
    "# Define MIONet instance (no Fourier, no final linear)\n",
    "model = MIMONet(\n",
    "    branch_arch_list=[\n",
    "        [branch_input_dim1, 512, 512, 512, dim],\n",
    "        [branch_input_dim2, 512, 512, 512, dim]\n",
    "    ],\n",
    "    trunk_arch=[trunk_input_dim, 256, 256, 256, dim],\n",
    "    num_outputs=3, \n",
    "    activation_fn=nn.ReLU,\n",
    "    merge_type='mul'  # or 'sum'\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Print parameter count\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {num_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eadbdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from training import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae939d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1E-6)\n",
    "#criterion = nn.MSELoss()\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fad6d9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "''' \n",
    "train_model(\n",
    "    model=model,\n",
    "    dataset=train_dataset,\n",
    "    optimizer = optimizer,\n",
    "    scheduler = None,\n",
    "    device='cuda',\n",
    "    num_epochs=5,\n",
    "    batch_size=4,\n",
    "    criterion= criterion,\n",
    "    patience=1000,\n",
    "    k_fold=5,\n",
    "    multi_gpu=False,\n",
    "    working_dir=\"\"\n",
    ")\n",
    "'''\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c336eb58",
   "metadata": {},
   "source": [
    "## Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fd9b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file not found. Please check the path.\n"
     ]
    }
   ],
   "source": [
    "# load the trained model (checkpoints/best_model.pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3c89059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path: /home/kazuma/Desktop/MIMONet/Subchannel/checkpoints/best_model.pt\n",
      "Exists: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MIMONet(\n",
       "  (branch_nets): ModuleList(\n",
       "    (0): FCN(\n",
       "      (network): Sequential(\n",
       "        (0): Linear(in_features=100, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=512, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (1): FCN(\n",
       "      (network): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=512, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (trunk_net): FCN(\n",
       "    (network): Sequential(\n",
       "      (0): Linear(in_features=2, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=256, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect where you're actually looking\n",
    "model_path = os.path.join(\".\", \"checkpoints\", \"best_model.pt\")\n",
    "print(\"Model path:\", os.path.abspath(model_path))\n",
    "print(\"Exists:\", os.path.exists(model_path))\n",
    "\n",
    "# Load the model\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ddf0027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_utils import test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8f69291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved test results to ./results/test_results.npz\n",
      "Mean relative L2 errors: [0.02211111 0.00268162 0.04149628]\n",
      "Standard deviation of relative L2 errors: [0.00022993 0.00116533 0.00037741]\n"
     ]
    }
   ],
   "source": [
    "test_model(\n",
    "    model=model,\n",
    "    test_loader=test_loader,\n",
    "    scaler=scaler,\n",
    "    working_dir='.',\n",
    "    device=device,\n",
    "    test_branch=test_branch,\n",
    "    save_array=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc713f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
