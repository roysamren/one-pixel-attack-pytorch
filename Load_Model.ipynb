{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "095bd9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e0ce6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# check if GPU is available and set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc5cd0e",
   "metadata": {},
   "source": [
    "### Model + Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cdd9afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory set to: /projects/bcnx/sroy6/One_pixel/one-pixel-attack-pytorch/src\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"src\")\n",
    "print(\"Current working directory set to:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbb894a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stty: 'standard input': Inappropriate ioctl for device\n"
     ]
    }
   ],
   "source": [
    "# Please put the src directory in the path\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), 'src'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "from utils import MIMONetDataset, ChannelScaler\n",
    "from mimonet import MIMONet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fd4ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set working directory\n",
    "working_dir = \"/projects/bcnx/kazumak2/MIMONet/HeatExchanger\"\n",
    "data_dir = os.path.join(working_dir, \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c88060c",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70a663fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trunk dataset\n",
    "trunk_input = np.load(os.path.join(data_dir, \"share/trunk.npz\"))['trunk']\n",
    "\n",
    "# min-max scaling [-1, 1]\n",
    "trunk_input[:, 0] = 2 * (trunk_input[:, 0] - np.min(trunk_input[:, 0])) / (np.max(trunk_input[:, 0]) - np.min(trunk_input[:, 0])) - 1\n",
    "trunk_input[:, 1] = 2 * (trunk_input[:, 1] - np.min(trunk_input[:, 1])) / (np.max(trunk_input[:, 1]) - np.min(trunk_input[:, 1])) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f697cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch1 shape: (1546, 2)\n",
      "Branch2 shape: (1546, 100)\n"
     ]
    }
   ],
   "source": [
    "# branch input dataset\n",
    "branch = np.load(os.path.join(data_dir, \"branch.npz\"))\n",
    "\n",
    "branch1 = branch['branch1']\n",
    "branch2 = branch['branch2']\n",
    "\n",
    "print(\"Branch1 shape:\", branch1.shape)\n",
    "print(\"Branch2 shape:\", branch2.shape)\n",
    "\n",
    "# split the dataset into training and testing sets\n",
    "train_size = int(0.8 * len(branch1))\n",
    "test_size = len(branch1) - train_size\n",
    "train_branch1, test_branch1 = branch1[:train_size], branch1[train_size:]\n",
    "train_branch2, test_branch2 = branch2[:train_size], branch2[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "572ff092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected output channels:\n",
      "pressure\n",
      "z-velocity\n",
      "y-velocity\n",
      "x-velocity\n",
      "velocity-magnitude\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary for the output channel names\n",
    "# 0: turb-kinetic-energy\n",
    "# 1: pressure\n",
    "# 2: temperature\n",
    "# 3: z-velocity\n",
    "# 4: y-velocity\n",
    "# 5: x-velocity\n",
    "# 6: velocity-magnitude\n",
    "\n",
    "dict_channel = {\n",
    "    0: 'turb-kinetic-energy',\n",
    "    1: 'pressure',\n",
    "    2: 'temperature',\n",
    "    3: 'z-velocity',\n",
    "    4: 'y-velocity',\n",
    "    5: 'x-velocity',\n",
    "    6: 'velocity-magnitude'\n",
    "}\n",
    "\n",
    "# select the output channel\n",
    "target_channel = [1, 3, 4, 5, 6]\n",
    "\n",
    "# print the selected output channel names\n",
    "# target_label is used to store the names of the selected output channels for further processing (e.g., plotting)\n",
    "print(\"Selected output channels:\")\n",
    "target_label = []\n",
    "for channel in target_channel:\n",
    "    print(dict_channel[channel])\n",
    "    target_label.append(dict_channel[channel])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "968677df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target dataset shape before split: (1546, 3977, 5)\n",
      "Train target shape: (1236, 3977, 5)\n",
      "Test target shape: (310, 3977, 5)\n"
     ]
    }
   ],
   "source": [
    "# target dataset\n",
    "target = np.load(os.path.join(data_dir, \"target.npy\"))\n",
    "\n",
    "# extract the output channels\n",
    "target = target[:, :, target_channel ]  # select the first 7 channels\n",
    "print(\"Target dataset shape before split:\", target.shape)\n",
    "\n",
    "\n",
    "# split the target dataset into training and testing sets\n",
    "train_target = target[:train_size]\n",
    "test_target = target[train_size:]\n",
    "\n",
    "print(\"Train target shape:\", train_target.shape)\n",
    "print(\"Test target shape:\", test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a13dd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of branch1: [  4.51454429 292.42944177]\n",
      "Std of branch1: [ 0.2615285  17.03323994]\n",
      "Mean of branch2: 12587.66968713018\n",
      "Std of branch2: 6302.709013835411\n"
     ]
    }
   ],
   "source": [
    "# get the mean and standard deviation of each channel\n",
    "mean_branch1 = np.mean(train_branch1, axis=0)\n",
    "std_branch1 = np.std(train_branch1, axis=0)\n",
    "\n",
    "print(\"Mean of branch1:\", mean_branch1)\n",
    "print(\"Std of branch1:\", std_branch1)\n",
    "\n",
    "# (# train samples, 100)\n",
    "mean_branch2 = np.mean(train_branch2)\n",
    "std_branch2 = np.std(train_branch2)\n",
    "\n",
    "print(\"Mean of branch2:\", mean_branch2)\n",
    "print(\"Std of branch2:\", std_branch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f8b0243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of normalized train_branch1: (1236, 2)\n",
      "Shape of normalized test_branch1: (310, 2)\n",
      "Shape of normalized train_branch2: (1236, 100)\n",
      "Shape of normalized test_branch2: (310, 100)\n"
     ]
    }
   ],
   "source": [
    "# normalize the branch data using the mean and std\n",
    "train_branch_1 = (train_branch1 - mean_branch1) / std_branch1\n",
    "test_branch_1 = (test_branch1 - mean_branch1) / std_branch1\n",
    "train_branch_2 = (train_branch2 - mean_branch2) / std_branch2\n",
    "test_branch_2 = (test_branch2 - mean_branch2) / std_branch2\n",
    "\n",
    "# print the shapes of the normalized data\n",
    "print(\"Shape of normalized train_branch1:\", train_branch_1.shape)\n",
    "print(\"Shape of normalized test_branch1:\", test_branch_1.shape)\n",
    "print(\"Shape of normalized train_branch2:\", train_branch_2.shape)\n",
    "print(\"Shape of normalized test_branch2:\", test_branch_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c339c659",
   "metadata": {},
   "source": [
    "### Scaling the target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2008bca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of scaled train_target: (1236, 3977, 5)\n",
      "Shape of scaled test_target: (310, 3977, 5)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# scaling the target data\n",
    "'''  \n",
    "note: reverse the scaling for the target data\n",
    "train_target = scaler.inverse_transform(train_target_scaled)\n",
    "test_target = scaler.inverse_transform(test_target_scaled)\n",
    "'''\n",
    "scaler = ChannelScaler(method='minmax', feature_range=(-1, 1))\n",
    "scaler.fit(train_target)\n",
    "train_target_scaled = scaler.transform(train_target)\n",
    "test_target_scaled = scaler.transform(test_target)\n",
    "\n",
    "print(\"Shape of scaled train_target:\", train_target_scaled.shape)\n",
    "print(\"Shape of scaled test_target:\", test_target_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fd2bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset and dataloader\n",
    "test_dataset = MIMONetDataset(\n",
    "    [test_branch_1, test_branch_2],  # branch_data_list\n",
    "    trunk_input,                     # trunk_data\n",
    "    test_target_scaled               # target_data\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,  # set to 1 for testing\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b72b2e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset and dataloader\n",
    "train_dataset = MIMONetDataset(\n",
    "    [train_branch_1, train_branch_2],  # branch_data_list\n",
    "    trunk_input,                     # trunk_data\n",
    "    train_target_scaled               # target_data\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,  # set to 1 for testing\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1e443f",
   "metadata": {},
   "source": [
    "## Model Instance & Load Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1460982d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture parameters\n",
    "dim = 256\n",
    "branch_input_dim1 = 2\n",
    "branch_input_dim2 = 100\n",
    "trunk_input_dim = 2\n",
    "\n",
    "# Define the model arguments for orig_MIMONet\n",
    "model_args = {\n",
    "    'branch_arch_list': [\n",
    "        [branch_input_dim1, 512, 512, 512, dim],\n",
    "        [branch_input_dim2, 512, 512, 512, dim]\n",
    "    ],\n",
    "    'trunk_arch': [trunk_input_dim, 256, 256, 256, dim],\n",
    "    'num_outputs': target.shape[-1] -1,  # number of output channels\n",
    "    'activation_fn': nn.ReLU,\n",
    "    'merge_type': 'mul',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f80d4ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trunk_input_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448bdfa2",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c73b408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from /projects/bcnx/kazumak2/MIMONet/HeatExchanger/checkpoints/custom_best_model_lambda_1E-4.pt\n",
      "Number of trainable parameters in the model: 1762052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2219693/821581263.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "model = MIMONet(**model_args).to(device)\n",
    "# Load the trained model\n",
    "model_path = os.path.join(working_dir, \"checkpoints/custom_best_model_lambda_1E-4.pt\")\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    print(\"Model loaded successfully from\", model_path)\n",
    "else:\n",
    "    print(\"Model file not found at\", model_path)\n",
    "    sys.exit(1)\n",
    "    \n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "\n",
    "# print the number of parameters in the model\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Number of trainable parameters in the model: {num_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088ef0dc",
   "metadata": {},
   "source": [
    "## How to predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fba8200d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n",
      "torch.Size([1, 3977, 2]) torch.Size([1, 3977, 5])\n"
     ]
    }
   ],
   "source": [
    "# feed the test loader to the model (and save predictions and targets)\n",
    "predictions = []\n",
    "targets = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        branch_data, trunk_data, target_data = batch\n",
    "        print(trunk_data.shape, target_data.shape)\n",
    "        branch_data = [b.to(device) for b in branch_data]\n",
    "        trunk_data = trunk_data.to(device)\n",
    "        target_data = target_data.to(device)\n",
    "\n",
    "        output = model(branch_data, trunk_data)\n",
    "        predictions.append(output.cpu().numpy())\n",
    "        targets.append(target_data.cpu().numpy())\n",
    "        \n",
    "# Convert predictions and targets to numpy arrays\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "targets = np.concatenate(targets, axis=0)\n",
    "\n",
    "# Reverse the scaling for the target data\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "targets = scaler.inverse_transform(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecf6df2",
   "metadata": {},
   "source": [
    "(Evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa1fa65b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3977, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2ffb990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 norm of predictions shape: (310, 4)\n",
      "L2 norm of targets shape: (310, 4)\n",
      "Mean relative L2 error per channel: [0.7996377  1.4521601  1.0151619  0.51779175] %\n",
      "Standard deviation of relative L2 error per channel: [0.00014584 0.0002911  0.0002742  0.00038389]\n"
     ]
    }
   ],
   "source": [
    "# Compute L2 norm over grid points for each sample and channel\n",
    "l2_pred = np.linalg.norm(predictions, axis=1)  # shape: (samples, channels)\n",
    "l2_gt = np.linalg.norm(targets[..., :4], axis=1)  # shape: (samples, channels)\n",
    "\n",
    "print(\"L2 norm of predictions shape:\", l2_pred.shape)\n",
    "print(\"L2 norm of targets shape:\", l2_gt.shape)\n",
    "\n",
    "\n",
    "# Compute L2 error over grid points for each sample and channel\n",
    "l2_err = np.linalg.norm(predictions - targets[..., :4], axis=1)  # shape: (samples, channels)\n",
    "\n",
    "# Compute relative error (avoid division by zero)\n",
    "rel_err = l2_err / (l2_gt + 1e-8)  # shape: (samples, channels)\n",
    "\n",
    "# Mean over samples for each channel\n",
    "mean_rel_err_per_channel = np.mean(rel_err, axis=0)  # shape: (channels,)\n",
    "\n",
    "print(\"Mean relative L2 error per channel:\", mean_rel_err_per_channel * 100, \"%\")\n",
    "\n",
    "# standard deviation of relative error per channel\n",
    "std_rel_err_per_channel = np.std(rel_err, axis=0)  # shape: (channels,)\n",
    "\n",
    "print(\"Standard deviation of relative L2 error per channel:\", std_rel_err_per_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aaa6fe39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (0.17.1+cu118)\n",
      "Requirement already satisfied: numpy in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: torch==2.2.1 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torchvision) (2.2.1+cu118)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: filelock in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (4.12.2)\n",
      "Requirement already satisfied: sympy in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (1.13.3)\n",
      "Requirement already satisfied: networkx in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (2025.5.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (8.7.0.84)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.19.3 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (11.8.86)\n",
      "Requirement already satisfied: triton==2.2.0 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from jinja2->torch==2.2.1->torchvision) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from sympy->torch==2.2.1->torchvision) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa50f9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "#import torchvision\n",
    "#import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11603cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Local file copied from the original repo – keep the path if needed.\n",
    "from differential_evolution import differential_evolution  # noqa: E402\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Utilities\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "'''def perturb_vector(xs: np.ndarray, base_vec: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Apply a batch of perturbations *xs* to *base_vec*.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xs : ndarray, shape (n_pop, 2*k) or (2*k,)\n",
    "        Genome(s) produced by DE: (idx₀, val₀, …).\n",
    "    base_vec : Tensor, shape (input_dim,)\n",
    "        Unperturbed input.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tensor, shape (n_pop, input_dim)\n",
    "        Batch of perturbed inputs ready for the model.\n",
    "    \"\"\"\n",
    "    if xs.ndim == 1:\n",
    "        xs = np.expand_dims(xs, 0)\n",
    "    n_pop, genome_len = xs.shape\n",
    "    k = genome_len // 2\n",
    "\n",
    "    # Duplicate the base vector n_pop times – stays on CPU for now.\n",
    "    vecs = base_vec.repeat(n_pop, 1)\n",
    "\n",
    "    for row, genome in enumerate(xs):\n",
    "        for j in range(k):\n",
    "            idx = int(round(genome[2 * j]))  # ensure integer index\n",
    "            val = genome[2 * j + 1]\n",
    "            idx_clamped = max(0, min(idx, base_vec.numel() - 1))\n",
    "            vecs[row, idx_clamped] = val\n",
    "    return vecs'''\n",
    "def perturb_vector(xs: np.ndarray, base_vec: torch.Tensor, order: str = \"2,100\"):\n",
    "    \"\"\"\n",
    "    Apply k-feature perturbations and split the result into [branch1, branch2].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xs : ndarray, shape (pop, 2*k) or (2*k,)\n",
    "        Genome(s): (idx₀, val₀, idx₁, val₁, ...).\n",
    "    base_vec : Tensor, shape (102,)\n",
    "        Original input.\n",
    "    order : str\n",
    "        \"100,2\"  → first 100 elements belong to branch **2**, last 2 to branch **1**.\n",
    "        \"2,100\" → opposite.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[Tensor] – [branch1, branch2]\n",
    "        branch1: (pop, 2)   branch2: (pop, 100)\n",
    "    \"\"\"\n",
    "    if xs.ndim == 1:\n",
    "        xs = xs[None]\n",
    "\n",
    "    pop, g_len = xs.shape\n",
    "    k = g_len // 2\n",
    "\n",
    "    # duplicate base\n",
    "    vecs = base_vec.repeat(pop, 1)\n",
    "\n",
    "    # overwrite selected indices\n",
    "    for r, genome in enumerate(xs):\n",
    "        for j in range(k):\n",
    "            idx = int(round(genome[2 * j]))\n",
    "            idx = max(0, min(idx, 101))\n",
    "            vecs[r, idx] = genome[2 * j + 1]\n",
    "\n",
    "    # split into branches\n",
    "    first_len, second_len = map(int, order.split(\",\"))\n",
    "    first, second = vecs[:, :first_len], vecs[:, first_len:]\n",
    "\n",
    "    if first_len == 100:\n",
    "        branch2, branch1 = first, second\n",
    "    else:\n",
    "        branch1, branch2 = first, second\n",
    "\n",
    "    return [branch1, branch2]\n",
    "\n",
    "\n",
    "def relative_l2_error(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Compute ‖pred ‑ target‖₂ / ‖target‖₂ along dim=1.\"\"\"\n",
    "    diff_norm = torch.norm(pred - target, dim=1)\n",
    "    tgt_norm = torch.norm(target, dim=1).clamp_min(1e-12)\n",
    "    return diff_norm / tgt_norm\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Attack core\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def de_objective(xs: np.ndarray, trunk : torch.Tensor ,base_x: torch.Tensor, y_true: torch.Tensor, model: torch.nn.Module,\n",
    "                 device: torch.device, maximize: bool = True) -> np.ndarray:\n",
    "    \"\"\"Vectorised objective for DE.  Returns *negative* error (to minimise).\"\"\"\n",
    "    perturbed = perturb_vector(xs, base_x).to(device)\n",
    "    N = perturbed[0].shape[0]\n",
    "    M = trunk.shape[1]\n",
    "    trunk_repeated = np.repeat(trunk, N, axis=0)  # shape: (N, M)\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(perturbed,trunk_repeated)\n",
    "    err = relative_l2_error(y_pred, y_true.to(device)).cpu().numpy()  # shape (n_pop,)\n",
    "    return -err if maximize else err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8a58c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_single(base_x: torch.Tensor, trunk : torch.Tensor,y_true: torch.Tensor, model: torch.nn.Module,\n",
    "                  features: int, error_thr: float, val_min: float, val_max: float,\n",
    "                  maxiter: int, popsize: int, device: torch.device, verbose: bool = False):\n",
    "    \"\"\"Run DE attack on a single (x, y) pair.  Returns (success, best_genome).\"\"\"\n",
    "    input_dim = base_x.numel()\n",
    "    bounds = []\n",
    "    for _ in range(features):\n",
    "        bounds.append((0, input_dim - 1))      # index\n",
    "        bounds.append((val_min, val_max))      # new value\n",
    "\n",
    "    # Pop‑multiplier like original code (total pop = popsize * n_params)\n",
    "    popmul = max(1, popsize)\n",
    "\n",
    "    predict_fn = lambda xs: de_objective(xs, trunk ,base_x, y_true, model, device, True)\n",
    "\n",
    "    def callback_fn(genome, convergence):\n",
    "        # Early stop if success achieved\n",
    "        perturbed = perturb_vector(genome, base_x).to(device)\n",
    "        with torch.no_grad():\n",
    "            err = relative_l2_error(model(perturbed,trunk), y_true.to(device))[0].item()\n",
    "        if verbose:\n",
    "            print(f\"  Current best error = {err:.3f}\")\n",
    "        return err > error_thr\n",
    "\n",
    "    # Optional initial population: random indices + gaussian values\n",
    "    n_params = 2 * features\n",
    "    inits = np.zeros((popmul * n_params, n_params))\n",
    "    for row in inits:\n",
    "        for f in range(features):\n",
    "            row[2 * f] = np.random.randint(0, input_dim)\n",
    "            row[2 * f + 1] = np.random.uniform(val_min, val_max)\n",
    "\n",
    "    result = differential_evolution(\n",
    "        predict_fn,\n",
    "        bounds,\n",
    "        maxiter=maxiter,\n",
    "        popsize=popmul,\n",
    "        recombination=1.0,\n",
    "        atol=-1,\n",
    "        init=inits,\n",
    "        polish=False,\n",
    "        callback=callback_fn,\n",
    "        disp=False,\n",
    "    )\n",
    "\n",
    "    # Evaluate final error\n",
    "    final_vec = perturb_vector(result.x, base_x).to(device)\n",
    "    with torch.no_grad():\n",
    "        final_err = relative_l2_error(model(final_vec,trunk), y_true.to(device))[0].item()\n",
    "    success = final_err > error_thr\n",
    "    return success, result.x, final_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e102c1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4118, -0.2055])\n",
      "tensor([ 7.1657e-02,  1.4694e+00, -1.5041e+00, -1.4588e-01,  1.3858e+00,\n",
      "        -3.3907e-01, -6.9457e-01, -1.7248e+00,  1.9702e-01, -3.1033e-01,\n",
      "         1.2570e+00, -2.0901e-01, -6.0942e-01,  1.4893e+00,  4.6194e-02,\n",
      "         6.4895e-01,  1.3773e+00,  4.8299e-01, -1.1637e+00, -7.3052e-01,\n",
      "        -3.1049e-01, -1.4529e-01, -1.3327e+00, -2.0520e-03,  1.5408e+00,\n",
      "        -5.7909e-01, -1.6663e+00,  6.8729e-01, -1.1725e+00, -2.0902e+00,\n",
      "         8.7214e-01,  5.6144e-01,  5.9701e-01, -2.8841e-01, -4.3935e-02,\n",
      "        -1.0143e+00,  4.5856e-01, -1.7392e+00,  7.7207e-02,  5.5173e-01,\n",
      "        -7.7296e-01, -5.0096e-01,  4.2643e-01,  4.1776e-01, -2.4072e-01,\n",
      "        -7.2021e-02, -9.8067e-01,  3.2405e-01,  1.2420e+00, -2.5561e-01,\n",
      "         1.1960e+00, -6.2417e-02, -1.0051e+00, -1.1167e-01, -4.1873e-01,\n",
      "         1.8051e+00,  2.0490e+00,  2.8978e-01, -5.5808e-01, -7.5048e-01,\n",
      "        -7.2617e-01,  1.3814e+00,  1.9167e-01, -5.0985e-01,  7.6611e-02,\n",
      "        -9.1556e-01,  8.8016e-01,  1.1884e+00, -4.1483e-01,  3.2813e-01,\n",
      "         1.5533e+00, -3.9075e-01,  1.4543e-01,  8.0441e-01,  3.3935e-01,\n",
      "        -1.2740e+00,  1.5550e+00, -4.7237e-01,  4.6506e-01,  4.2974e-01,\n",
      "         6.7259e-02, -1.3151e+00, -8.8599e-01, -7.5132e-03, -1.9510e-01,\n",
      "        -9.2474e-01, -9.8794e-01,  5.3973e-02,  1.0514e-01,  9.1276e-01,\n",
      "        -5.0852e-01,  6.2637e-01,  6.5871e-01, -1.1825e+00,  2.1168e-01,\n",
      "         1.5923e+00,  3.5442e-02,  1.0938e+00, -6.4001e-01,  6.5587e-01])\n",
      "tensor([-4.1177e-01, -2.0548e-01,  7.1657e-02,  1.4694e+00, -1.5041e+00,\n",
      "        -1.4588e-01,  1.3858e+00, -3.3907e-01, -6.9457e-01, -1.7248e+00,\n",
      "         1.9702e-01, -3.1033e-01,  1.2570e+00, -2.0901e-01, -6.0942e-01,\n",
      "         1.4893e+00,  4.6194e-02,  6.4895e-01,  1.3773e+00,  4.8299e-01,\n",
      "        -1.1637e+00, -7.3052e-01, -3.1049e-01, -1.4529e-01, -1.3327e+00,\n",
      "        -2.0520e-03,  1.5408e+00, -5.7909e-01, -1.6663e+00,  6.8729e-01,\n",
      "        -1.1725e+00, -2.0902e+00,  8.7214e-01,  5.6144e-01,  5.9701e-01,\n",
      "        -2.8841e-01, -4.3935e-02, -1.0143e+00,  4.5856e-01, -1.7392e+00,\n",
      "         7.7207e-02,  5.5173e-01, -7.7296e-01, -5.0096e-01,  4.2643e-01,\n",
      "         4.1776e-01, -2.4072e-01, -7.2021e-02, -9.8067e-01,  3.2405e-01,\n",
      "         1.2420e+00, -2.5561e-01,  1.1960e+00, -6.2417e-02, -1.0051e+00,\n",
      "        -1.1167e-01, -4.1873e-01,  1.8051e+00,  2.0490e+00,  2.8978e-01,\n",
      "        -5.5808e-01, -7.5048e-01, -7.2617e-01,  1.3814e+00,  1.9167e-01,\n",
      "        -5.0985e-01,  7.6611e-02, -9.1556e-01,  8.8016e-01,  1.1884e+00,\n",
      "        -4.1483e-01,  3.2813e-01,  1.5533e+00, -3.9075e-01,  1.4543e-01,\n",
      "         8.0441e-01,  3.3935e-01, -1.2740e+00,  1.5550e+00, -4.7237e-01,\n",
      "         4.6506e-01,  4.2974e-01,  6.7259e-02, -1.3151e+00, -8.8599e-01,\n",
      "        -7.5132e-03, -1.9510e-01, -9.2474e-01, -9.8794e-01,  5.3973e-02,\n",
      "         1.0514e-01,  9.1276e-01, -5.0852e-01,  6.2637e-01,  6.5871e-01,\n",
      "        -1.1825e+00,  2.1168e-01,  1.5923e+00,  3.5442e-02,  1.0938e+00,\n",
      "        -6.4001e-01,  6.5587e-01])\n",
      "Concatenated shape: torch.Size([102])\n",
      "Recovered tensors:\n",
      "a: tensor([-0.4118, -0.2055])\n",
      "b: tensor([ 7.1657e-02,  1.4694e+00, -1.5041e+00, -1.4588e-01,  1.3858e+00,\n",
      "        -3.3907e-01, -6.9457e-01, -1.7248e+00,  1.9702e-01, -3.1033e-01,\n",
      "         1.2570e+00, -2.0901e-01, -6.0942e-01,  1.4893e+00,  4.6194e-02,\n",
      "         6.4895e-01,  1.3773e+00,  4.8299e-01, -1.1637e+00, -7.3052e-01,\n",
      "        -3.1049e-01, -1.4529e-01, -1.3327e+00, -2.0520e-03,  1.5408e+00,\n",
      "        -5.7909e-01, -1.6663e+00,  6.8729e-01, -1.1725e+00, -2.0902e+00,\n",
      "         8.7214e-01,  5.6144e-01,  5.9701e-01, -2.8841e-01, -4.3935e-02,\n",
      "        -1.0143e+00,  4.5856e-01, -1.7392e+00,  7.7207e-02,  5.5173e-01,\n",
      "        -7.7296e-01, -5.0096e-01,  4.2643e-01,  4.1776e-01, -2.4072e-01,\n",
      "        -7.2021e-02, -9.8067e-01,  3.2405e-01,  1.2420e+00, -2.5561e-01,\n",
      "         1.1960e+00, -6.2417e-02, -1.0051e+00, -1.1167e-01, -4.1873e-01,\n",
      "         1.8051e+00,  2.0490e+00,  2.8978e-01, -5.5808e-01, -7.5048e-01,\n",
      "        -7.2617e-01,  1.3814e+00,  1.9167e-01, -5.0985e-01,  7.6611e-02,\n",
      "        -9.1556e-01,  8.8016e-01,  1.1884e+00, -4.1483e-01,  3.2813e-01,\n",
      "         1.5533e+00, -3.9075e-01,  1.4543e-01,  8.0441e-01,  3.3935e-01,\n",
      "        -1.2740e+00,  1.5550e+00, -4.7237e-01,  4.6506e-01,  4.2974e-01,\n",
      "         6.7259e-02, -1.3151e+00, -8.8599e-01, -7.5132e-03, -1.9510e-01,\n",
      "        -9.2474e-01, -9.8794e-01,  5.3973e-02,  1.0514e-01,  9.1276e-01,\n",
      "        -5.0852e-01,  6.2637e-01,  6.5871e-01, -1.1825e+00,  2.1168e-01,\n",
      "         1.5923e+00,  3.5442e-02,  1.0938e+00, -6.4001e-01,  6.5587e-01])\n",
      "a shape: torch.Size([2])\n",
      "b shape: torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# Create a torch tensor of size 2 and another of size 100\n",
    "a = torch.randn(2)\n",
    "b = torch.randn(100)\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "# Concatenate them into a single tensor of size 102\n",
    "c = torch.cat([a, b])\n",
    "print(c)\n",
    "print(\"Concatenated shape:\", c.shape)   \n",
    "# Separate them back into the original shapes\n",
    "a_recovered = c[:2]\n",
    "b_recovered = c[2:]\n",
    "\n",
    "print(\"Recovered tensors:\")\n",
    "print(\"a:\", a_recovered)\n",
    "print(\"b:\", b_recovered)\n",
    "print(\"a shape:\", a_recovered.shape)\n",
    "print(\"b shape:\", b_recovered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae7ff143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7efd102c2d90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2412d76",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'torch.device' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdevice\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'torch.device' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "device[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a127ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "device() received an invalid combination of arguments - got (tuple), but expected one of:\n * (torch.device device)\n      didn't match because some of the arguments have invalid types: (!tuple of (str,)!)\n * (str type, int index = -1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: device() received an invalid combination of arguments - got (tuple), but expected one of:\n * (torch.device device)\n      didn't match because some of the arguments have invalid types: (!tuple of (str,)!)\n * (str type, int index = -1)\n"
     ]
    }
   ],
   "source": [
    "torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4525d731",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cat() received an invalid combination of arguments - got (Tensor, builtin_function_or_method), but expected one of:\n * (tuple of Tensors tensors, int dim = 0, *, Tensor out = None)\n * (tuple of Tensors tensors, name dim, *, Tensor out = None)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     36\u001b[0m     branch_data, trunk_data, target_data \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m---> 37\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbranch_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbranch_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# assuming branch_data is a list of tensors\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     trunk_data \u001b[38;5;241m=\u001b[39m trunk_data\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     39\u001b[0m     y \u001b[38;5;241m=\u001b[39m target_data\n",
      "\u001b[0;31mTypeError\u001b[0m: cat() received an invalid combination of arguments - got (Tensor, builtin_function_or_method), but expected one of:\n * (tuple of Tensors tensors, int dim = 0, *, Tensor out = None)\n * (tuple of Tensors tensors, name dim, *, Tensor out = None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "branch_order = (2, 100),    # (len_first, len_second)  (100→branch2 first)\n",
    "features   = 5,             # k — how many components attacker may change\n",
    "error_thr  = 0.30,          # success threshold (relative ℓ₂ error)\n",
    "val_min    = -1.0,          # allowed range for perturbed value\n",
    "val_max    =  1.0,\n",
    "samples    = 20,            # how many dataset rows to attack\n",
    "\n",
    "# DE hyper-params\n",
    "maxiter    = 150,\n",
    "popsize    = 400,\n",
    "\n",
    "# misc\n",
    "seed       = 0,\n",
    "device     = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "verbose    = False,\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "device = torch.device(device[0])\n",
    "\n",
    "# Load model – works for either full pickled model or state_dict\n",
    "model_obj = model\n",
    "model = model_obj if isinstance(model_obj, torch.nn.Module) else None\n",
    "if model is None:\n",
    "    raise ValueError(\"Provide a saved *model object*, not just a state_dict – ease of use.\")\n",
    "model.eval()\n",
    "\n",
    "# TODO: replace RegressionDataset with your own data loader\n",
    "#dataset = RegressionDataset(n_samples=args.samples, seed=args.seed)\n",
    "loader = train_loader\n",
    "\n",
    "successes = 0\n",
    "total = 0\n",
    "\n",
    "for batch in train_loader:\n",
    "    branch_data, trunk_data, target_data = batch\n",
    "    x = torch.cat(branch_data[0].squeeze(0),branch_data[1].squeeze)  # assuming branch_data is a list of tensors\n",
    "    trunk_data = trunk_data.squeeze(0)\n",
    "    y = target_data\n",
    "\n",
    "    success, genome, err = attack_single(\n",
    "        x.cpu(),trunk_data.cpu(), y.cpu(),model,\n",
    "        features=features,\n",
    "        error_thr=error_thr,\n",
    "        val_min=val_min,\n",
    "        val_max=val_max,\n",
    "        maxiter=maxiter,\n",
    "        popsize=popsize,\n",
    "        device=device,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    total += 1\n",
    "    successes += int(success)\n",
    "\n",
    "    status = \"✔\" if success else \"✘\"\n",
    "    print(f\"[{i+1:03d}] {status}  final error = {err:.3f}  success‑rate = {successes / total:.3%}\")\n",
    "\n",
    "print(f\"\\nFinal success rate over {total} samples: {successes / total:.2%}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e654c948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-wave_env]",
   "language": "python",
   "name": "conda-env-.conda-wave_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
