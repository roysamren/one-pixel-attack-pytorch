{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "095bd9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e0ce6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# check if GPU is available and set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc5cd0e",
   "metadata": {},
   "source": [
    "### Model + Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cdd9afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory set to: /projects/bcnx/sroy6/One_pixel/one-pixel-attack-pytorch/src\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"src\")\n",
    "print(\"Current working directory set to:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbb894a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stty: 'standard input': Inappropriate ioctl for device\n"
     ]
    }
   ],
   "source": [
    "# Please put the src directory in the path\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), 'src'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "from utils import MIMONetDataset, ChannelScaler\n",
    "from mimonet import MIMONet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fd4ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set working directory\n",
    "working_dir = \"/projects/bcnx/kazumak2/MIMONet/HeatExchanger\"\n",
    "data_dir = os.path.join(working_dir, \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c88060c",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70a663fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trunk dataset\n",
    "trunk_input = np.load(os.path.join(data_dir, \"share/trunk.npz\"))['trunk']\n",
    "\n",
    "# min-max scaling [-1, 1]\n",
    "trunk_input[:, 0] = 2 * (trunk_input[:, 0] - np.min(trunk_input[:, 0])) / (np.max(trunk_input[:, 0]) - np.min(trunk_input[:, 0])) - 1\n",
    "trunk_input[:, 1] = 2 * (trunk_input[:, 1] - np.min(trunk_input[:, 1])) / (np.max(trunk_input[:, 1]) - np.min(trunk_input[:, 1])) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f697cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch1 shape: (1546, 2)\n",
      "Branch2 shape: (1546, 100)\n"
     ]
    }
   ],
   "source": [
    "# branch input dataset\n",
    "branch = np.load(os.path.join(data_dir, \"branch.npz\"))\n",
    "\n",
    "branch1 = branch['branch1']\n",
    "branch2 = branch['branch2']\n",
    "\n",
    "print(\"Branch1 shape:\", branch1.shape)\n",
    "print(\"Branch2 shape:\", branch2.shape)\n",
    "\n",
    "# split the dataset into training and testing sets\n",
    "train_size = int(0.8 * len(branch1))\n",
    "test_size = len(branch1) - train_size\n",
    "train_branch1, test_branch1 = branch1[:train_size], branch1[train_size:]\n",
    "train_branch2, test_branch2 = branch2[:train_size], branch2[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "572ff092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected output channels:\n",
      "pressure\n",
      "z-velocity\n",
      "y-velocity\n",
      "x-velocity\n",
      "velocity-magnitude\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary for the output channel names\n",
    "# 0: turb-kinetic-energy\n",
    "# 1: pressure\n",
    "# 2: temperature\n",
    "# 3: z-velocity\n",
    "# 4: y-velocity\n",
    "# 5: x-velocity\n",
    "# 6: velocity-magnitude\n",
    "\n",
    "dict_channel = {\n",
    "    0: 'turb-kinetic-energy',\n",
    "    1: 'pressure',\n",
    "    2: 'temperature',\n",
    "    3: 'z-velocity',\n",
    "    4: 'y-velocity',\n",
    "    5: 'x-velocity',\n",
    "    6: 'velocity-magnitude'\n",
    "}\n",
    "\n",
    "# select the output channel\n",
    "target_channel = [1, 3, 4, 5, 6]\n",
    "\n",
    "# print the selected output channel names\n",
    "# target_label is used to store the names of the selected output channels for further processing (e.g., plotting)\n",
    "print(\"Selected output channels:\")\n",
    "target_label = []\n",
    "for channel in target_channel:\n",
    "    print(dict_channel[channel])\n",
    "    target_label.append(dict_channel[channel])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "968677df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target dataset shape before split: (1546, 3977, 5)\n",
      "Train target shape: (1236, 3977, 5)\n",
      "Test target shape: (310, 3977, 5)\n"
     ]
    }
   ],
   "source": [
    "# target dataset\n",
    "target = np.load(os.path.join(data_dir, \"target.npy\"))\n",
    "\n",
    "# extract the output channels\n",
    "target = target[:, :, target_channel ]  # select the first 7 channels\n",
    "print(\"Target dataset shape before split:\", target.shape)\n",
    "\n",
    "\n",
    "# split the target dataset into training and testing sets\n",
    "train_target = target[:train_size]\n",
    "test_target = target[train_size:]\n",
    "\n",
    "print(\"Train target shape:\", train_target.shape)\n",
    "print(\"Test target shape:\", test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a13dd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of branch1: [  4.51454429 292.42944177]\n",
      "Std of branch1: [ 0.2615285  17.03323994]\n",
      "Mean of branch2: 12587.66968713018\n",
      "Std of branch2: 6302.709013835411\n"
     ]
    }
   ],
   "source": [
    "# get the mean and standard deviation of each channel\n",
    "mean_branch1 = np.mean(train_branch1, axis=0)\n",
    "std_branch1 = np.std(train_branch1, axis=0)\n",
    "\n",
    "print(\"Mean of branch1:\", mean_branch1)\n",
    "print(\"Std of branch1:\", std_branch1)\n",
    "\n",
    "# (# train samples, 100)\n",
    "mean_branch2 = np.mean(train_branch2)\n",
    "std_branch2 = np.std(train_branch2)\n",
    "\n",
    "print(\"Mean of branch2:\", mean_branch2)\n",
    "print(\"Std of branch2:\", std_branch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f8b0243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of normalized train_branch1: (1236, 2)\n",
      "Shape of normalized test_branch1: (310, 2)\n",
      "Shape of normalized train_branch2: (1236, 100)\n",
      "Shape of normalized test_branch2: (310, 100)\n"
     ]
    }
   ],
   "source": [
    "# normalize the branch data using the mean and std\n",
    "train_branch_1 = (train_branch1 - mean_branch1) / std_branch1\n",
    "test_branch_1 = (test_branch1 - mean_branch1) / std_branch1\n",
    "train_branch_2 = (train_branch2 - mean_branch2) / std_branch2\n",
    "test_branch_2 = (test_branch2 - mean_branch2) / std_branch2\n",
    "\n",
    "# print the shapes of the normalized data\n",
    "print(\"Shape of normalized train_branch1:\", train_branch_1.shape)\n",
    "print(\"Shape of normalized test_branch1:\", test_branch_1.shape)\n",
    "print(\"Shape of normalized train_branch2:\", train_branch_2.shape)\n",
    "print(\"Shape of normalized test_branch2:\", test_branch_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c339c659",
   "metadata": {},
   "source": [
    "### Scaling the target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2008bca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of scaled train_target: (1236, 3977, 5)\n",
      "Shape of scaled test_target: (310, 3977, 5)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# scaling the target data\n",
    "'''  \n",
    "note: reverse the scaling for the target data\n",
    "train_target = scaler.inverse_transform(train_target_scaled)\n",
    "test_target = scaler.inverse_transform(test_target_scaled)\n",
    "'''\n",
    "scaler = ChannelScaler(method='minmax', feature_range=(-1, 1))\n",
    "scaler.fit(train_target)\n",
    "train_target_scaled = scaler.transform(train_target)\n",
    "test_target_scaled = scaler.transform(test_target)\n",
    "\n",
    "print(\"Shape of scaled train_target:\", train_target_scaled.shape)\n",
    "print(\"Shape of scaled test_target:\", test_target_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fd2bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset and dataloader\n",
    "test_dataset = MIMONetDataset(\n",
    "    [test_branch_1, test_branch_2],  # branch_data_list\n",
    "    trunk_input,                     # trunk_data\n",
    "    test_target_scaled               # target_data\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,  # set to 1 for testing\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b72b2e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset and dataloader\n",
    "train_dataset = MIMONetDataset(\n",
    "    [train_branch_1, train_branch_2],  # branch_data_list\n",
    "    trunk_input,                     # trunk_data\n",
    "    train_target_scaled               # target_data\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,  # set to 1 for testing\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1e443f",
   "metadata": {},
   "source": [
    "## Model Instance & Load Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1460982d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture parameters\n",
    "dim = 256\n",
    "branch_input_dim1 = 2\n",
    "branch_input_dim2 = 100\n",
    "trunk_input_dim = 2\n",
    "\n",
    "# Define the model arguments for orig_MIMONet\n",
    "model_args = {\n",
    "    'branch_arch_list': [\n",
    "        [branch_input_dim1, 512, 512, 512, dim],\n",
    "        [branch_input_dim2, 512, 512, 512, dim]\n",
    "    ],\n",
    "    'trunk_arch': [trunk_input_dim, 256, 256, 256, dim],\n",
    "    'num_outputs': target.shape[-1] -1,  # number of output channels\n",
    "    'activation_fn': nn.ReLU,\n",
    "    'merge_type': 'mul',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f80d4ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trunk_input_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448bdfa2",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c73b408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from /projects/bcnx/kazumak2/MIMONet/HeatExchanger/checkpoints/custom_best_model_lambda_1E-4.pt\n",
      "Number of trainable parameters in the model: 1762052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_312039/821581263.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "model = MIMONet(**model_args).to(device)\n",
    "# Load the trained model\n",
    "model_path = os.path.join(working_dir, \"checkpoints/custom_best_model_lambda_1E-4.pt\")\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    print(\"Model loaded successfully from\", model_path)\n",
    "else:\n",
    "    print(\"Model file not found at\", model_path)\n",
    "    sys.exit(1)\n",
    "    \n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "\n",
    "# print the number of parameters in the model\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Number of trainable parameters in the model: {num_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088ef0dc",
   "metadata": {},
   "source": [
    "## How to predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fba8200d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n",
      "target_data shape: torch.Size([1, 3977, 5])\n",
      "Output shape: torch.Size([1, 3977, 4])\n"
     ]
    }
   ],
   "source": [
    "# feed the test loader to the model (and save predictions and targets)\n",
    "predictions = []\n",
    "targets = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        branch_data, trunk_data, target_data = batch\n",
    "        #print(branch_data)\n",
    "        #print(trunk_data.shape, target_data.shape)\n",
    "        branch_data = [b.to(device) for b in branch_data]\n",
    "        trunk_data = trunk_data.to(device)\n",
    "        target_data = target_data.to(device)\n",
    "        print(\"target_data shape:\", target_data.shape)\n",
    "\n",
    "        output = model(branch_data, trunk_data)\n",
    "        print(\"Output shape:\", output.shape)\n",
    "        predictions.append(output.cpu().numpy())\n",
    "        targets.append(target_data.cpu().numpy())\n",
    "        \n",
    "# Convert predictions and targets to numpy arrays\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "targets = np.concatenate(targets, axis=0)\n",
    "\n",
    "# Reverse the scaling for the target data\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "targets = scaler.inverse_transform(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecf6df2",
   "metadata": {},
   "source": [
    "(Evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2ffb990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 norm of predictions shape: (310, 4)\n",
      "L2 norm of targets shape: (310, 4)\n",
      "Mean relative L2 error per channel: [0.7996377 1.4521604 1.0151619 0.5177918] %\n",
      "Standard deviation of relative L2 error per channel: [0.00014584 0.0002911  0.0002742  0.00038389]\n"
     ]
    }
   ],
   "source": [
    "# Compute L2 norm over grid points for each sample and channel\n",
    "l2_pred = np.linalg.norm(predictions, axis=1)  # shape: (samples, channels)\n",
    "l2_gt = np.linalg.norm(targets[..., :4], axis=1)  # shape: (samples, channels)\n",
    "\n",
    "print(\"L2 norm of predictions shape:\", l2_pred.shape)\n",
    "print(\"L2 norm of targets shape:\", l2_gt.shape)\n",
    "\n",
    "\n",
    "# Compute L2 error over grid points for each sample and channel\n",
    "l2_err = np.linalg.norm(predictions - targets[..., :4], axis=1)  # shape: (samples, channels)\n",
    "\n",
    "# Compute relative error (avoid division by zero)\n",
    "rel_err = l2_err / (l2_gt + 1e-8)  # shape: (samples, channels)\n",
    "\n",
    "# Mean over samples for each channel\n",
    "mean_rel_err_per_channel = np.mean(rel_err, axis=0)  # shape: (channels,)\n",
    "\n",
    "print(\"Mean relative L2 error per channel:\", mean_rel_err_per_channel * 100, \"%\")\n",
    "\n",
    "# standard deviation of relative error per channel\n",
    "std_rel_err_per_channel = np.std(rel_err, axis=0)  # shape: (channels,)\n",
    "\n",
    "print(\"Standard deviation of relative L2 error per channel:\", std_rel_err_per_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aaa6fe39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (0.17.1+cu118)\n",
      "Requirement already satisfied: numpy in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: torch==2.2.1 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torchvision) (2.2.1+cu118)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: filelock in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (4.12.2)\n",
      "Requirement already satisfied: sympy in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (1.13.3)\n",
      "Requirement already satisfied: networkx in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (2025.5.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (8.7.0.84)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.19.3 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (11.8.86)\n",
      "Requirement already satisfied: triton==2.2.0 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from torch==2.2.1->torchvision) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from jinja2->torch==2.2.1->torchvision) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /u/sroy6/.conda/envs/wave_env/lib/python3.9/site-packages (from sympy->torch==2.2.1->torchvision) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa50f9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "#import torchvision\n",
    "#import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11603cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Local file copied from the original repo – keep the path if needed.\n",
    "from differential_evolution import differential_evolution  # noqa: E402\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Utilities\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "'''def perturb_vector(xs: np.ndarray, base_vec: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Apply a batch of perturbations *xs* to *base_vec*.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xs : ndarray, shape (n_pop, 2*k) or (2*k,)\n",
    "        Genome(s) produced by DE: (idx₀, val₀, …).\n",
    "    base_vec : Tensor, shape (input_dim,)\n",
    "        Unperturbed input.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tensor, shape (n_pop, input_dim)\n",
    "        Batch of perturbed inputs ready for the model.\n",
    "    \"\"\"\n",
    "    if xs.ndim == 1:\n",
    "        xs = np.expand_dims(xs, 0)\n",
    "    n_pop, genome_len = xs.shape\n",
    "    k = genome_len // 2\n",
    "\n",
    "    # Duplicate the base vector n_pop times – stays on CPU for now.\n",
    "    vecs = base_vec.repeat(n_pop, 1)\n",
    "\n",
    "    for row, genome in enumerate(xs):\n",
    "        for j in range(k):\n",
    "            idx = int(round(genome[2 * j]))  # ensure integer index\n",
    "            val = genome[2 * j + 1]\n",
    "            idx_clamped = max(0, min(idx, base_vec.numel() - 1))\n",
    "            vecs[row, idx_clamped] = val\n",
    "    return vecs'''\n",
    "def perturb_vector(xs: np.ndarray, base_vec: torch.Tensor, order: str = \"2,100\"):\n",
    "    \"\"\"\n",
    "    Apply k-feature perturbations and split the result into [branch1, branch2].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xs : ndarray, shape (pop, 2*k) or (2*k,)\n",
    "        Genome(s): (idx₀, val₀, idx₁, val₁, ...).\n",
    "    base_vec : Tensor, shape (102,)\n",
    "        Original input.\n",
    "    order : str\n",
    "        \"100,2\"  → first 100 elements belong to branch **2**, last 2 to branch **1**.\n",
    "        \"2,100\" → opposite.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[Tensor] – [branch1, branch2]\n",
    "        branch1: (pop, 2)   branch2: (pop, 100)\n",
    "    \"\"\"\n",
    "    if xs.ndim == 1:\n",
    "        xs = xs[None]\n",
    "\n",
    "    pop, g_len = xs.shape\n",
    "    k = g_len // 2\n",
    "\n",
    "    # duplicate base\n",
    "    vecs = base_vec.repeat(pop, 1)\n",
    "\n",
    "    # overwrite selected indices\n",
    "    for r, genome in enumerate(xs):\n",
    "        for j in range(k):\n",
    "            idx = int(round(genome[2 * j]))\n",
    "            idx = max(0, min(idx, 101))\n",
    "            vecs[r, idx] = genome[2 * j + 1]\n",
    "\n",
    "    # split into branches\n",
    "    first_len, second_len = map(int, order.split(\",\"))\n",
    "    first, second = vecs[:, :first_len], vecs[:, first_len:]\n",
    "\n",
    "    if first_len == 100:\n",
    "        branch2, branch1 = first, second\n",
    "    else:\n",
    "        branch1, branch2 = first, second\n",
    "\n",
    "    return [branch1, branch2]\n",
    "\n",
    "\n",
    "def relative_l2_error(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Compute ‖pred ‑ target‖₂ / ‖target‖₂ along dim=1.\"\"\"\n",
    "    pred_flat = pred.view(pred.size(0), -1)        # (B, N)\n",
    "    tgt_flat  = target.view(target.size(0),  -1)         # (1 or B, N)\n",
    "    diff_norm = torch.norm(pred_flat - tgt_flat, dim=1)      # (B,)\n",
    "    tgt_norm  = torch.norm(tgt_flat,           dim=1).clamp_min(1e-12)\n",
    "    return diff_norm / tgt_norm                 # (B,)\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Attack core\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def de_objective(xs: np.ndarray, trunk : torch.Tensor ,base_x: torch.Tensor, y_true: torch.Tensor, model: torch.nn.Module,\n",
    "                 device: torch.device, maximize: bool = True) -> np.ndarray:\n",
    "    \"\"\"Vectorised objective for DE.  Returns *negative* error (to minimise).\"\"\"\n",
    "    #print(perturb_vector(xs, base_x))\n",
    "    perturbed = perturb_vector(xs, base_x)\n",
    "    #print(\"perturbed shape:\", perturbed[0].shape, perturbed[1].shape)\n",
    "    #print(trunk.shape)\n",
    "    N = perturbed[0].shape[0]\n",
    "    M = trunk.shape[1]\n",
    "    trunk_repeated = np.repeat(trunk.unsqueeze(0), N, axis=0)  # shape: (N, M)\n",
    "    #print(\"trunk_repeated shape:\", trunk_repeated.shape)\n",
    "    branch_data = [b.to(device) for b in perturbed]\n",
    "    trunk_data = trunk_repeated.to(device)\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(branch_data,trunk_data)\n",
    "        #print(y_true.shape)\n",
    "        #print(\"y_pred shape:\", y_pred.shape)\n",
    "    err = relative_l2_error(y_pred, y_true[..., :-1].to(device)).cpu().numpy()  # shape (n_pop,)\n",
    "    return -err if maximize else err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8a58c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_single(base_x: torch.Tensor, trunk : torch.Tensor,y_true: torch.Tensor, model: torch.nn.Module,\n",
    "                  features: int, error_thr: float, val_min: float, val_max: float,\n",
    "                  maxiter: int, popsize: int, device: torch.device, verbose: bool = False):\n",
    "    \"\"\"Run DE attack on a single (x, y) pair.  Returns (success, best_genome).\"\"\"\n",
    "    input_dim = base_x.numel()\n",
    "    bounds = []\n",
    "    for _ in range(features):\n",
    "        bounds.append((0, input_dim - 1))      # index\n",
    "        bounds.append((val_min, val_max))      # new value\n",
    "\n",
    "    # Pop‑multiplier like original code (total pop = popsize * n_params)\n",
    "    popmul = max(1, popsize)\n",
    "\n",
    "    predict_fn = lambda xs: de_objective(xs, trunk ,base_x, y_true, model, device, True)\n",
    "\n",
    "    def callback_fn(genome, convergence):\n",
    "        # Early stop if success achieved\n",
    "        #print(perturb_vector(genome, base_x))\n",
    "        perturbed = perturb_vector(genome, base_x)\n",
    "        N = perturbed[0].shape[0]\n",
    "        M = trunk.shape[1]\n",
    "        trunk_repeated = np.repeat(trunk.unsqueeze(0), N, axis=0)\n",
    "        #print(trunk.shape)\n",
    "        #print(\"trunk_repeated shape:\", trunk_repeated.shape)\n",
    "        branch_data = [b.to(device) for b in perturbed]\n",
    "        trunk_data = trunk_repeated.to(device)\n",
    "        #print(y_true.shape, y_true.to(device).shape)\n",
    "        with torch.no_grad():\n",
    "            err = relative_l2_error(model(branch_data,trunk_data), y_true[..., :-1].to(device))[0].item()\n",
    "        if verbose:\n",
    "            #print(f\"  Current best error = {err:.3f}\")\n",
    "            return err > error_thr\n",
    "\n",
    "    # Optional initial population: random indices + gaussian values\n",
    "    n_params = 2 * features\n",
    "    inits = np.zeros((popmul * n_params, n_params))\n",
    "    for row in inits:\n",
    "        for f in range(features):\n",
    "            row[2 * f] = np.random.randint(0, input_dim)\n",
    "            row[2 * f + 1] = np.random.uniform(val_min, val_max)\n",
    "\n",
    "    result = differential_evolution(\n",
    "        predict_fn,\n",
    "        bounds,\n",
    "        maxiter=maxiter,\n",
    "        popsize=popmul,\n",
    "        recombination=1.0,\n",
    "        atol=-1,\n",
    "        init=inits,\n",
    "        polish=False,\n",
    "        callback=callback_fn,\n",
    "        disp=False,\n",
    "    )\n",
    "\n",
    "    # Evaluate final error\n",
    "    final_vec = perturb_vector(result.x, base_x)\n",
    "    N = 1\n",
    "    trunk_repeated = np.repeat(trunk.unsqueeze(0), N, axis=0)\n",
    "    branch_data = [b.to(device) for b in final_vec]\n",
    "    trunk_data = trunk_repeated.to(device)\n",
    "    print(\"Final perturbation vector:\", final_vec)\n",
    "    with torch.no_grad():\n",
    "        final_err = relative_l2_error(model(branch_data,trunk_data), y_true[..., :-1].to(device))[0].item()\n",
    "    success = final_err > error_thr\n",
    "    return success, result.x, final_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e102c1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.7152, -0.4830])\n",
      "tensor([ 1.3936e+00,  2.8651e+00, -1.8754e-01,  3.5915e-01,  1.2271e+00,\n",
      "        -6.3693e-01, -1.1878e+00, -1.0521e+00, -4.8623e-01, -6.4652e-02,\n",
      "        -9.6079e-01, -9.9639e-02, -2.2714e-01,  6.3441e-01,  1.1389e+00,\n",
      "         1.8847e-02, -6.9575e-01,  7.5030e-01,  1.7319e-01,  2.2245e-02,\n",
      "         1.0565e-01, -2.2264e+00,  8.6724e-02, -1.2917e+00,  4.5140e-01,\n",
      "         1.6095e+00,  7.0999e-01, -1.5737e+00, -1.3861e+00, -5.6575e-01,\n",
      "        -1.6844e+00,  1.4107e+00,  2.6972e-01,  1.1717e+00,  3.4070e-01,\n",
      "         1.0726e+00, -2.7380e-02, -2.0773e-01, -3.5589e-01,  1.3271e+00,\n",
      "        -2.4709e+00,  2.8799e-02,  2.8969e-01,  9.8595e-01,  1.7958e+00,\n",
      "         6.9583e-01, -2.3813e+00, -8.7861e-02,  9.5456e-02, -1.5391e+00,\n",
      "        -6.0368e-01, -5.5237e-01,  8.7076e-02, -8.2761e-01,  9.5607e-01,\n",
      "        -1.3935e-01, -3.0227e-01,  1.4422e+00,  8.5122e-01, -5.7162e-01,\n",
      "        -1.6833e-02,  5.8310e-01,  8.0127e-01,  1.1665e+00, -8.0526e-01,\n",
      "        -8.6265e-01,  9.7688e-01,  2.9382e-01, -1.2289e+00,  1.0983e+00,\n",
      "         5.5332e-01,  1.0078e-01, -5.4594e-02,  1.3349e-01, -8.6375e-01,\n",
      "        -8.0209e-01, -2.5992e-01, -3.0877e-01, -1.6494e+00, -1.4569e+00,\n",
      "        -3.1266e-01,  1.0905e-01,  1.3360e+00,  2.8207e-01,  6.3533e-01,\n",
      "        -4.0797e-01,  1.2804e+00,  9.0837e-01, -1.0898e+00, -1.7074e+00,\n",
      "        -1.4232e+00,  5.1374e-01, -2.2190e-03, -1.8855e+00, -1.3549e-01,\n",
      "         1.4348e+00,  2.2369e+00,  1.2262e-01, -1.5283e+00, -5.9132e-01])\n",
      "tensor([ 1.7152e+00, -4.8304e-01,  1.3936e+00,  2.8651e+00, -1.8754e-01,\n",
      "         3.5915e-01,  1.2271e+00, -6.3693e-01, -1.1878e+00, -1.0521e+00,\n",
      "        -4.8623e-01, -6.4652e-02, -9.6079e-01, -9.9639e-02, -2.2714e-01,\n",
      "         6.3441e-01,  1.1389e+00,  1.8847e-02, -6.9575e-01,  7.5030e-01,\n",
      "         1.7319e-01,  2.2245e-02,  1.0565e-01, -2.2264e+00,  8.6724e-02,\n",
      "        -1.2917e+00,  4.5140e-01,  1.6095e+00,  7.0999e-01, -1.5737e+00,\n",
      "        -1.3861e+00, -5.6575e-01, -1.6844e+00,  1.4107e+00,  2.6972e-01,\n",
      "         1.1717e+00,  3.4070e-01,  1.0726e+00, -2.7380e-02, -2.0773e-01,\n",
      "        -3.5589e-01,  1.3271e+00, -2.4709e+00,  2.8799e-02,  2.8969e-01,\n",
      "         9.8595e-01,  1.7958e+00,  6.9583e-01, -2.3813e+00, -8.7861e-02,\n",
      "         9.5456e-02, -1.5391e+00, -6.0368e-01, -5.5237e-01,  8.7076e-02,\n",
      "        -8.2761e-01,  9.5607e-01, -1.3935e-01, -3.0227e-01,  1.4422e+00,\n",
      "         8.5122e-01, -5.7162e-01, -1.6833e-02,  5.8310e-01,  8.0127e-01,\n",
      "         1.1665e+00, -8.0526e-01, -8.6265e-01,  9.7688e-01,  2.9382e-01,\n",
      "        -1.2289e+00,  1.0983e+00,  5.5332e-01,  1.0078e-01, -5.4594e-02,\n",
      "         1.3349e-01, -8.6375e-01, -8.0209e-01, -2.5992e-01, -3.0877e-01,\n",
      "        -1.6494e+00, -1.4569e+00, -3.1266e-01,  1.0905e-01,  1.3360e+00,\n",
      "         2.8207e-01,  6.3533e-01, -4.0797e-01,  1.2804e+00,  9.0837e-01,\n",
      "        -1.0898e+00, -1.7074e+00, -1.4232e+00,  5.1374e-01, -2.2190e-03,\n",
      "        -1.8855e+00, -1.3549e-01,  1.4348e+00,  2.2369e+00,  1.2262e-01,\n",
      "        -1.5283e+00, -5.9132e-01])\n",
      "Concatenated shape: torch.Size([102])\n",
      "Recovered tensors:\n",
      "a: tensor([ 1.7152, -0.4830])\n",
      "b: tensor([ 1.3936e+00,  2.8651e+00, -1.8754e-01,  3.5915e-01,  1.2271e+00,\n",
      "        -6.3693e-01, -1.1878e+00, -1.0521e+00, -4.8623e-01, -6.4652e-02,\n",
      "        -9.6079e-01, -9.9639e-02, -2.2714e-01,  6.3441e-01,  1.1389e+00,\n",
      "         1.8847e-02, -6.9575e-01,  7.5030e-01,  1.7319e-01,  2.2245e-02,\n",
      "         1.0565e-01, -2.2264e+00,  8.6724e-02, -1.2917e+00,  4.5140e-01,\n",
      "         1.6095e+00,  7.0999e-01, -1.5737e+00, -1.3861e+00, -5.6575e-01,\n",
      "        -1.6844e+00,  1.4107e+00,  2.6972e-01,  1.1717e+00,  3.4070e-01,\n",
      "         1.0726e+00, -2.7380e-02, -2.0773e-01, -3.5589e-01,  1.3271e+00,\n",
      "        -2.4709e+00,  2.8799e-02,  2.8969e-01,  9.8595e-01,  1.7958e+00,\n",
      "         6.9583e-01, -2.3813e+00, -8.7861e-02,  9.5456e-02, -1.5391e+00,\n",
      "        -6.0368e-01, -5.5237e-01,  8.7076e-02, -8.2761e-01,  9.5607e-01,\n",
      "        -1.3935e-01, -3.0227e-01,  1.4422e+00,  8.5122e-01, -5.7162e-01,\n",
      "        -1.6833e-02,  5.8310e-01,  8.0127e-01,  1.1665e+00, -8.0526e-01,\n",
      "        -8.6265e-01,  9.7688e-01,  2.9382e-01, -1.2289e+00,  1.0983e+00,\n",
      "         5.5332e-01,  1.0078e-01, -5.4594e-02,  1.3349e-01, -8.6375e-01,\n",
      "        -8.0209e-01, -2.5992e-01, -3.0877e-01, -1.6494e+00, -1.4569e+00,\n",
      "        -3.1266e-01,  1.0905e-01,  1.3360e+00,  2.8207e-01,  6.3533e-01,\n",
      "        -4.0797e-01,  1.2804e+00,  9.0837e-01, -1.0898e+00, -1.7074e+00,\n",
      "        -1.4232e+00,  5.1374e-01, -2.2190e-03, -1.8855e+00, -1.3549e-01,\n",
      "         1.4348e+00,  2.2369e+00,  1.2262e-01, -1.5283e+00, -5.9132e-01])\n",
      "a shape: torch.Size([2])\n",
      "b shape: torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# Create a torch tensor of size 2 and another of size 100\n",
    "a = torch.randn(2)\n",
    "b = torch.randn(100)\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "# Concatenate them into a single tensor of size 102\n",
    "c = torch.cat([a, b])\n",
    "print(c)\n",
    "print(\"Concatenated shape:\", c.shape)   \n",
    "# Separate them back into the original shapes\n",
    "a_recovered = c[:2]\n",
    "b_recovered = c[2:]\n",
    "\n",
    "print(\"Recovered tensors:\")\n",
    "print(\"a:\", a_recovered)\n",
    "print(\"b:\", b_recovered)\n",
    "print(\"a shape:\", a_recovered.shape)\n",
    "print(\"b shape:\", b_recovered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae7ff143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa4468aa6b0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4525d731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final perturbation vector: [tensor([[-0.9964,  0.6351]]), tensor([[ 0.8806, -1.8958,  0.9102, -1.6935, -1.5928, -1.4925, -1.3926, -1.2934,\n",
      "         -1.1949, -1.0972, -1.0004, -0.9046, -0.8100, -0.7165, -0.6243, -0.5334,\n",
      "         -0.4441, -0.3563, -0.2702, -0.1858, -0.1032, -0.0225,  0.0561,  0.1327,\n",
      "          0.2072,  0.2794,  0.3494,  0.4170,  0.4821,  0.5448,  0.6049,  0.6624,\n",
      "          0.7172,  0.7692,  0.8185,  0.8650,  0.9085,  0.9492,  0.9868,  1.0215,\n",
      "          1.0531,  1.0817,  1.1072,  1.1295,  1.1487,  1.1647,  1.1775,  1.1871,\n",
      "          1.1936,  1.1968,  1.1968,  1.1936,  1.1871,  1.1775,  1.1647,  1.1487,\n",
      "          1.1295,  1.1072,  1.0817,  1.0531,  1.0215,  0.9868,  0.9492,  0.9085,\n",
      "          0.8650,  0.8185,  0.7692,  0.7172,  0.6624,  0.6049,  0.5448,  0.4821,\n",
      "          0.4170,  0.3494,  0.2794,  0.2072,  0.1327,  0.0561, -0.0225, -0.1032,\n",
      "         -0.1858, -0.2702, -0.3563, -0.4441, -0.5334, -0.6243, -0.7165, -0.8100,\n",
      "         -0.9046, -1.0004, -1.0972, -1.1949, -1.2934, -1.3926, -1.4925, -1.5928,\n",
      "         -1.6935, -1.7946,  0.9811,  0.9142]])]\n",
      "False\n",
      "Final perturbation vector: [tensor([[0.9998, 0.0437]]), tensor([[-1.9972, -1.8943, -1.7916, -1.6891, -1.5869, -1.4851, -1.3838, -1.2831,\n",
      "         -1.1831, -1.0840, -0.9858, -0.8886, -0.7925, -0.6977, -0.6041, -0.5119,\n",
      "         -0.4213, -0.3322, -0.2448, -0.1592, -0.9985, -0.9995,  0.0863,  0.1640,\n",
      "          0.2395,  0.3128,  0.3838,  0.4524,  0.5185,  0.5821,  0.6431,  0.7014,\n",
      "          0.7570,  0.8098,  0.8598,  0.9070,  0.9512,  0.9924,  1.0306,  1.0658,\n",
      "          1.0979,  1.1269,  1.1527,  1.1754,  1.1948,  1.2111,  1.2241,  1.2339,\n",
      "          1.2404,  1.2437,  1.2437,  1.2404,  1.2339,  1.2241,  1.2111,  1.1948,\n",
      "          1.1754,  1.1527,  1.1269,  1.0979,  1.0658,  1.0306,  0.9924,  0.9512,\n",
      "          0.9070,  0.8598,  0.8098,  0.7570,  0.7014,  0.6431,  0.5821,  0.5185,\n",
      "          0.4524,  0.3838,  0.3128,  0.2395,  0.1640,  0.0863, -0.9894, -0.9910,\n",
      "         -0.1592, -0.2448, -0.3322, -0.4213, -0.5119, -0.6041, -0.6977, -0.7925,\n",
      "         -0.8886, -0.9858, -1.0840, -1.1831, -1.2831, -1.3838, -1.4851, -1.5869,\n",
      "         -1.6891, -1.7916, -1.8943, -1.9972]])]\n",
      "True\n",
      "Final perturbation vector: [tensor([[0.9992, 0.2604]]), tensor([[-1.9972, -1.8941, -1.7912, -1.6885, -1.5860, -1.4840, -1.3825, -1.2817,\n",
      "         -1.1815, -1.0822, -0.9838, -0.8864, -0.7901, -0.6951, -0.6013, -0.5090,\n",
      "         -0.4181, -0.3289, -0.2413, -0.1555, -0.9968, -0.9996,  0.0904,  0.1683,\n",
      "          0.2440,  0.3175,  0.3886,  0.4573,  0.5236,  0.5873,  0.6484,  0.7068,\n",
      "          0.7625,  0.8155,  0.8656,  0.9128,  0.9571,  0.9984,  1.0367,  1.0720,\n",
      "          1.1041,  1.1332,  1.1590,  1.1817,  1.2012,  1.2175,  1.2306,  1.2404,\n",
      "          1.2469,  1.2502,  1.2502,  1.2469,  1.2404,  1.2306,  1.2175,  1.2012,\n",
      "          1.1817,  1.1590,  1.1332,  1.1041,  1.0720,  1.0367,  0.9984,  0.9571,\n",
      "          0.9128,  0.8656,  0.8155,  0.7625,  0.7068,  0.6484,  0.5873,  0.5236,\n",
      "          0.4573,  0.3886,  0.3175,  0.2440,  0.1683,  0.0904, -0.9955, -0.9884,\n",
      "         -0.1555, -0.2413, -0.3289, -0.4181, -0.5090, -0.6013, -0.6951, -0.7901,\n",
      "         -0.8864, -0.9838, -1.0822, -1.1815, -1.2817, -1.3825, -1.4840, -1.5860,\n",
      "         -1.6885, -1.7912, -1.8941, -1.9972]])]\n",
      "True\n",
      "Final perturbation vector: [tensor([[-0.9996,  1.4513]]), tensor([[ 0.9834,  0.7235, -1.7761, -1.6659, -1.5559, -1.4465, -1.3375, -1.2293,\n",
      "         -1.1218, -1.0152, -0.9096, -0.8051, -0.7017, -0.5997, -0.4991, -0.4000,\n",
      "         -0.3025, -0.2067, -0.1128, -0.0207,  0.0694,  0.1574,  0.2433,  0.3269,\n",
      "          0.4081,  0.4869,  0.5633,  0.6370,  0.7081,  0.7765,  0.8421,  0.9048,\n",
      "          0.9646,  1.0214,  1.0752,  1.1258,  1.1734,  1.2177,  1.2588,  1.2967,\n",
      "          1.3312,  1.3623,  1.3901,  1.4145,  1.4354,  1.4529,  1.4669,  1.4774,\n",
      "          1.4844,  1.4879,  1.4879,  1.4844,  1.4774,  1.4669,  1.4529,  1.4354,\n",
      "          1.4145,  1.3901,  1.3623,  1.3312,  1.2967,  1.2588,  1.2177,  1.1734,\n",
      "          1.1258,  1.0752,  1.0214,  0.9646,  0.9048,  0.8421,  0.7765,  0.7081,\n",
      "          0.6370,  0.5633,  0.4869,  0.4081,  0.3269,  0.2433,  0.1574,  0.0694,\n",
      "         -0.0207, -0.1128, -0.2067, -0.3025, -0.4000, -0.4991, -0.5997, -0.7017,\n",
      "         -0.8051, -0.9096, -1.0152, -1.1218, -1.2293, -1.3375, -1.4465, -1.5559,\n",
      "         -1.6659, -1.7761,  0.9565,  0.9982]])]\n",
      "False\n",
      "Final perturbation vector: [tensor([[-0.9983,  1.6119]]), tensor([[ 0.8845, -1.9008, -1.8046, -1.7085, -1.6127, -1.5173, -1.4224, -1.3281,\n",
      "         -1.2345, -1.1416, -1.0496, -0.9585, -0.8685, -0.7796, -0.6919, -0.6056,\n",
      "         -0.5206, -0.4372, -0.3553, -0.2751, -0.1966, -0.1199, -0.0451,  0.0278,\n",
      "          0.0986,  0.1672,  0.2337,  0.2980,  0.3599,  0.4195,  0.4766,  0.5313,\n",
      "          0.5834,  0.6329,  0.6797,  0.7239,  0.7653,  0.8040,  0.8398,  0.8727,\n",
      "          0.9028,  0.9300,  0.9542,  0.9754,  0.9936,  1.0089,  1.0211,  1.0302,\n",
      "          1.0363,  1.0394,  1.0394,  1.0363,  1.0302,  1.0211,  1.0089,  0.9936,\n",
      "          0.9754,  0.9542,  0.9300,  0.9028,  0.8727,  0.8398,  0.8040,  0.7653,\n",
      "          0.7239,  0.6797,  0.6329,  0.5834,  0.5313,  0.4766,  0.4195,  0.3599,\n",
      "          0.2980,  0.2337,  0.1672,  0.0986,  0.0278, -0.0451, -0.1199, -0.1966,\n",
      "         -0.2751, -0.3553, -0.4372, -0.5206, -0.6056, -0.6919, -0.7796, -0.8685,\n",
      "         -0.9585, -1.0496, -1.1416, -1.2345, -1.3281, -1.4224, -1.5173, -1.6127,\n",
      "          0.9808,  0.9521, -1.9008,  0.9661]])]\n",
      "False\n",
      "Final perturbation vector: [tensor([[ 0.9997, -0.3714]]), tensor([[-1.9972, -1.8975, -1.7979, -1.6985, -1.5994, -1.5007, -1.4025, -1.3048,\n",
      "         -1.2079, -1.1118, -1.0166, -0.9224, -0.8292, -0.7372, -0.6465, -0.5572,\n",
      "         -0.4693, -0.3829, -0.2982, -0.9981, -0.9964, -0.9932,  0.0228,  0.0982,\n",
      "          0.1714,  0.2425,  0.3113,  0.3778,  0.4419,  0.5035,  0.5627,  0.6192,\n",
      "          0.6731,  0.7243,  0.7728,  0.8185,  0.8614,  0.9014,  0.9384,  0.9725,\n",
      "          1.0036,  1.0317,  1.0568,  1.0788,  1.0976,  1.1134,  1.1260,  1.1355,\n",
      "          1.1418,  1.1450,  1.1450,  1.1418,  1.1355,  1.1260,  1.1134,  1.0976,\n",
      "          1.0788,  1.0568,  1.0317,  1.0036,  0.9725,  0.9384,  0.9014,  0.8614,\n",
      "          0.8185,  0.7728,  0.7243,  0.6731,  0.6192,  0.5627,  0.5035,  0.4419,\n",
      "          0.3778,  0.3113,  0.2425,  0.1714,  0.0982,  0.0228, -0.9995, -0.1339,\n",
      "         -0.2152, -0.2982, -0.3829, -0.4693, -0.5572, -0.6465, -0.7372, -0.8292,\n",
      "         -0.9224, -1.0166, -1.1118, -1.2079, -1.3048, -1.4025, -1.5007, -1.5994,\n",
      "         -1.6985, -1.7979, -1.8975, -1.9972]])]\n",
      "True\n",
      "Final perturbation vector: [tensor([[0.9998, 1.6918]]), tensor([[-1.9972, -1.9042, -1.8112, -1.7185, -1.6261, -1.5340, -1.4424, -1.3513,\n",
      "         -1.2609, -1.1712, -1.0824, -0.9945, -0.9076, -0.8218, -0.7372, -0.6538,\n",
      "         -0.5718, -0.4912, -0.4122, -0.3347, -0.2590, -0.9955, -0.1127, -0.0424,\n",
      "          0.0259,  0.0922,  0.1564,  0.2184,  0.2782,  0.3357,  0.3909,  0.4436,\n",
      "          0.4939,  0.5417,  0.5870,  0.6296,  0.6696,  0.7069,  0.7414,  0.7733,\n",
      "          0.8023,  0.8285,  0.8519,  0.8724,  0.8900,  0.9047,  0.9164,  0.9253,\n",
      "          0.9312,  0.9341,  0.9341,  0.9312,  0.9253,  0.9164,  0.9047,  0.8900,\n",
      "          0.8724,  0.8519,  0.8285,  0.8023,  0.7733,  0.7414,  0.7069,  0.6696,\n",
      "          0.6296,  0.5870,  0.5417,  0.4939,  0.4436,  0.3909,  0.3357,  0.2782,\n",
      "          0.2184,  0.1564,  0.0922,  0.0259, -0.0424, -0.9977, -0.9918, -0.9980,\n",
      "         -0.3347, -0.4122, -0.4912, -0.5718, -0.6538, -0.7372, -0.8218, -0.9076,\n",
      "         -0.9945, -1.0824, -1.1712, -1.2609, -1.3513, -1.4424, -1.5340, -1.6261,\n",
      "         -1.7185, -1.8112, -1.9042, -1.9972]])]\n",
      "True\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m trunk_data \u001b[38;5;241m=\u001b[39m trunk_data\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     35\u001b[0m y \u001b[38;5;241m=\u001b[39m target_data\n\u001b[0;32m---> 36\u001b[0m success, genome, err \u001b[38;5;241m=\u001b[39m \u001b[43mattack_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrunk_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_thr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_thr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_min\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpopsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpopsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     48\u001b[0m successes \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(success)\n",
      "Cell \u001b[0;32mIn[23], line 42\u001b[0m, in \u001b[0;36mattack_single\u001b[0;34m(base_x, trunk, y_true, model, features, error_thr, val_min, val_max, maxiter, popsize, device, verbose)\u001b[0m\n\u001b[1;32m     39\u001b[0m         row[\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m f] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, input_dim)\n\u001b[1;32m     40\u001b[0m         row[\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m f \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(val_min, val_max)\n\u001b[0;32m---> 42\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mdifferential_evolution\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredict_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpopsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpopmul\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecombination\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpolish\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Evaluate final error\u001b[39;00m\n\u001b[1;32m     56\u001b[0m final_vec \u001b[38;5;241m=\u001b[39m perturb_vector(result\u001b[38;5;241m.\u001b[39mx, base_x)\n",
      "File \u001b[0;32m/projects/bcnx/sroy6/One_pixel/one-pixel-attack-pytorch/src/differential_evolution.py:49\u001b[0m, in \u001b[0;36mdifferential_evolution\u001b[0;34m(func, bounds, args, strategy, maxiter, popsize, tol, mutation, recombination, seed, callback, disp, polish, init, atol)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03mFind the global minimum of a multivariate function using differential evolution.\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m(Code shortened for brevity; see original for full docstring.)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m solver \u001b[38;5;241m=\u001b[39m DifferentialEvolutionSolver(func, bounds, args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m     42\u001b[0m                                      strategy\u001b[38;5;241m=\u001b[39mstrategy, maxiter\u001b[38;5;241m=\u001b[39mmaxiter,\n\u001b[1;32m     43\u001b[0m                                      popsize\u001b[38;5;241m=\u001b[39mpopsize, tol\u001b[38;5;241m=\u001b[39mtol,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m                                      callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m     48\u001b[0m                                      disp\u001b[38;5;241m=\u001b[39mdisp, init\u001b[38;5;241m=\u001b[39minit, atol\u001b[38;5;241m=\u001b[39matol)\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projects/bcnx/sroy6/One_pixel/one-pixel-attack-pytorch/src/differential_evolution.py:189\u001b[0m, in \u001b[0;36mDifferentialEvolutionSolver.solve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nit \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxiter \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m         warning_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/projects/bcnx/sroy6/One_pixel/one-pixel-attack-pytorch/src/differential_evolution.py:275\u001b[0m, in \u001b[0;36mDifferentialEvolutionSolver.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_constraint(trial)\n\u001b[1;32m    274\u001b[0m parameters \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scale_parameters(trial) \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m trials])\n\u001b[0;32m--> 275\u001b[0m energies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m itersize\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m candidate, (energy, trial) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(energies, trials)):\n",
      "Cell \u001b[0;32mIn[23], line 14\u001b[0m, in \u001b[0;36mattack_single.<locals>.<lambda>\u001b[0;34m(xs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Pop‑multiplier like original code (total pop = popsize * n_params)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m popmul \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m1\u001b[39m, popsize)\n\u001b[0;32m---> 14\u001b[0m predict_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m xs: \u001b[43mde_objective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mbase_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcallback_fn\u001b[39m(genome, convergence):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Early stop if success achieved\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m#print(perturb_vector(genome, base_x))\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     perturbed \u001b[38;5;241m=\u001b[39m perturb_vector(genome, base_x)\n",
      "Cell \u001b[0;32mIn[22], line 124\u001b[0m, in \u001b[0;36mde_objective\u001b[0;34m(xs, trunk, base_x, y_true, model, device, maximize)\u001b[0m\n\u001b[1;32m    121\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model(branch_data,trunk_data)\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m#print(y_true.shape)\u001b[39;00m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;66;03m#print(\"y_pred shape:\", y_pred.shape)\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m err \u001b[38;5;241m=\u001b[39m relative_l2_error(y_pred, \u001b[43my_true\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# shape (n_pop,)\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39merr \u001b[38;5;28;01mif\u001b[39;00m maximize \u001b[38;5;28;01melse\u001b[39;00m err\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "branch_order = (2, 100)   # (len_first, len_second)  (100→branch2 first)\n",
    "features   = 10     # k — how many components attacker may change\n",
    "error_thr  = 0.30     # success threshold (relative ℓ₂ error)\n",
    "val_min    = -1.0        # allowed range for perturbed value\n",
    "val_max    =  1.0\n",
    "maxiter    = 150\n",
    "popsize    = 40\n",
    "seed       = 0\n",
    "device     = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "verbose    = False\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "device = torch.device(device)\n",
    "\n",
    "# Load model – works for either full pickled model or state_dict\n",
    "model_obj = model\n",
    "model = model_obj if isinstance(model_obj, torch.nn.Module) else None\n",
    "if model is None:\n",
    "    raise ValueError(\"Provide a saved *model object*, not just a state_dict – ease of use.\")\n",
    "model.eval()\n",
    "\n",
    "# TODO: replace RegressionDataset with your own data loader\n",
    "loader = train_loader\n",
    "\n",
    "successes = 0\n",
    "total = 0\n",
    "\n",
    "for batch in train_loader:\n",
    "    branch_data, trunk_data, target_data = batch\n",
    "    b1 = branch_data[0].squeeze(0)\n",
    "    b2 = branch_data[1].squeeze(0)\n",
    "    x = torch.cat([b1,b2])  # assuming branch_data is a list of tensors\n",
    "    trunk_data = trunk_data.squeeze(0)\n",
    "    y = target_data\n",
    "    success, genome, err = attack_single(\n",
    "        x.cpu(),trunk_data.cpu(), y.cpu(),model,\n",
    "        features=5,\n",
    "        error_thr=error_thr,\n",
    "        val_min=val_min,\n",
    "        val_max=val_max,\n",
    "        maxiter=maxiter,\n",
    "        popsize=popsize,\n",
    "        device=device,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "    total += 1\n",
    "    successes += int(success)\n",
    "    status = \"✔\" if success else \"✘\"\n",
    "    print(successes)\n",
    "    #print(f\"[{i+1:03d}] {status}  final error = {err:.3f}  success‑rate = {successes / total:.3%}\")\n",
    "\n",
    "print(f\"\\nFinal success rate over {total} samples: {successes / total:.2%}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "460e6ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "successes/total"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-wave_env]",
   "language": "python",
   "name": "conda-env-.conda-wave_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
